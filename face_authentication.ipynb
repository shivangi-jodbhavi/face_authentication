{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "face_authentication.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN4NOcFBZHR7sXo2YEuF1Pp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivangi-jodbhavi/face_authentication/blob/master/face_authentication.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfKdYdxE0Y-i"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "import time\n",
        "from datetime import datetime\n",
        "from uuid import uuid4\n",
        "\n",
        "import cv2\n",
        "import insightface\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Import necessary libraries\n",
        "from flask import Flask, Response, render_template, request\n",
        "from insightface.app import FaceAnalysis\n",
        "from insightface.data import get_image as ins_get_image\n",
        "from numpy.lib.npyio import save\n",
        "from sklearn import metrics\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "cwd = os.path.dirname(os.path.abspath(__file__))\n",
        "print('Setting current working directory to:', cwd)\n",
        "os.chdir(cwd)\n",
        "\n",
        "app = Flask(__name__, template_folder='./templates')\n",
        "\n",
        "\n",
        "TRAIN_EMBEDDINGS_PATH = r'project\\embeddings\\train'\n",
        "NEW_USER_EMBEDDINGS_PATH = r'project\\embeddings\\new_users'\n",
        "\n",
        "TRAIN_IMAGES_PATH = r'project\\images\\train'\n",
        "TEST_IMAGES_PATH = r'project\\images\\test'\n",
        "NEW_USER_IMAGES_PATH = r'project\\images\\new_users'\n",
        "\n",
        "NUM_FRAMES_FOR_AUTHENTICATION = 20\n",
        "MAX_NEW_USER_IMAGES = 5\n",
        "\n",
        "FPS_MAX = 10  # not less than 5\n",
        "H = 1280\n",
        "W = 720\n",
        "SCALE = 1  # not more than 3\n",
        "\n",
        "\n",
        "def visualize_results(image, boxes, identities, scores):\n",
        "    image = np.uint8(image)\n",
        "    boxes = np.array(boxes, dtype=np.int32)\n",
        "\n",
        "    for box, identity, score in zip(boxes, identities, scores):\n",
        "        text = '{} | {:.2f}'.format(identity, score)\n",
        "        text_orig = (box[0] + 5, box[1] - 6)\n",
        "        image = cv2.putText(\n",
        "            image,\n",
        "            text,\n",
        "            text_orig,\n",
        "            cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
        "            .45, [0, 0, 0],\n",
        "            4,\n",
        "            lineType=cv2.LINE_AA)\n",
        "        image = cv2.putText(\n",
        "            image,\n",
        "            text,\n",
        "            text_orig,\n",
        "            cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
        "            .45, [255, 255, 255],\n",
        "            1,\n",
        "            lineType=cv2.LINE_AA)\n",
        "        image = cv2.rectangle(\n",
        "            image, (box[0], box[1]),\n",
        "            (box[2], box[3]),\n",
        "            [255, 0, 0], 1)\n",
        "    return image\n",
        "\n",
        "\n",
        "def imshow(image, figsize=(16, 9), mode=None):\n",
        "    if mode == 'bgr':\n",
        "        image = image[:, :, ::-1]\n",
        "\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(np.uint8(image))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def get_randon_identifier():\n",
        "    return str(uuid4())\n",
        "\n",
        "def read_image(path):\n",
        "    return cv2.imread(path)\n",
        "\n",
        "\n",
        "def crop_image(image, box):\n",
        "    x1, y1, x2, y2 = np.int32(box)\n",
        "    cropped_image = image[y1:y2, x1:x2, :]\n",
        "    return cropped_image\n",
        "\n",
        "\n",
        "def get_embeddings(image):\n",
        "    boxes = []\n",
        "    embeddings = []\n",
        "    faces = detection.get(image)\n",
        "    for face in faces:\n",
        "        embeddings.append(recognition.get(image, face))\n",
        "        boxes.append(face['bbox'])\n",
        "    embeddings = np.array(embeddings)\n",
        "    boxes = np.array(boxes)\n",
        "    return embeddings, boxes\n",
        "\n",
        "\n",
        "def run(knn, image, index_to_identity):\n",
        "    embeddings, boxes = get_embeddings(image)\n",
        "    probs = knn.predict_proba(embeddings)\n",
        "    labels = np.argmax(probs, axis=-1)\n",
        "    scores = np.max(probs, axis=-1)\n",
        "    identities = [index_to_identity[label] for label in labels]\n",
        "\n",
        "    for i, score in enumerate(scores):\n",
        "        if score > 0.9:\n",
        "            continue\n",
        "        identities[i] = 'UNKNOWN'\n",
        "\n",
        "    viz_image = visualize_results(image.copy(), boxes, identities, scores)\n",
        "    return viz_image, identities, boxes\n",
        "\n",
        "\n",
        "def get_models():\n",
        "    detection = FaceAnalysis(allowed_modules=['detection'])\n",
        "    recognition = insightface.model_zoo.get_model(r'project\\webface_r50.onnx')\n",
        "\n",
        "    detection.prepare(ctx_id=0, det_size=(640, 640))\n",
        "    recognition.prepare(ctx_id=0)\n",
        "    return detection, recognition\n",
        "\n",
        "\n",
        "detection, recognition = get_models()\n",
        "\n",
        "def dump_train_embeddings():\n",
        "    train_images = glob.glob(os.path.join(TRAIN_IMAGES_PATH, '*'))\n",
        "\n",
        "    for folder in train_images:\n",
        "        for img_path in glob.glob(os.path.join(folder, '*')):\n",
        "            img = cv2.imread(img_path)\n",
        "            faces = detection.get(img)\n",
        "            feature = recognition.get(img, faces[0])\n",
        "\n",
        "            person_name = os.path.basename(folder)\n",
        "            image_name = os.path.basename(img_path).split('.')[0]\n",
        "            output_path = os.path.join(\n",
        "                TRAIN_EMBEDDINGS_PATH, person_name, image_name + '.npy')\n",
        "\n",
        "            os.makedirs(\n",
        "                os.path.join(TRAIN_EMBEDDINGS_PATH, person_name),\n",
        "                exist_ok=True)\n",
        "            np.save(output_path, feature)\n",
        "\n",
        "\n",
        "def dump_new_user_embedding(img, person_name, idx):\n",
        "    faces = detection.get(img)\n",
        "    feature = recognition.get(img, faces[0])\n",
        "\n",
        "    output_path = os.path.join(\n",
        "        NEW_USER_EMBEDDINGS_PATH, person_name, str(idx) + '.npy')\n",
        "\n",
        "    os.makedirs(\n",
        "        os.path.join(NEW_USER_EMBEDDINGS_PATH, person_name),\n",
        "        exist_ok=True)\n",
        "    np.save(output_path, feature)\n",
        "\n",
        "\n",
        "def train():\n",
        "    train_embeddings = glob.glob(os.path.join(TRAIN_EMBEDDINGS_PATH, '*'))\n",
        "    new_user_embeddings = glob.glob(os.path.join(NEW_USER_EMBEDDINGS_PATH, '*'))\n",
        "\n",
        "    print('Found {} train identities'.format(len(train_embeddings)))\n",
        "    print('Found {} new identities'.format(len(new_user_embeddings)))\n",
        "\n",
        "    identities = []\n",
        "    features = []\n",
        "    for folder in train_embeddings + new_user_embeddings:\n",
        "        person = os.path.basename(folder)\n",
        "        folder = os.path.join(folder, '*')\n",
        "        for path in glob.glob(folder):\n",
        "            assert path.endswith('.npy')\n",
        "            features.append(np.load(path))\n",
        "            identities.append(person)\n",
        "\n",
        "    features = np.array(features)\n",
        "    identities = np.array(identities)\n",
        "\n",
        "    #\n",
        "    labels = sorted(list(set(identities)))\n",
        "    index_to_identity = {i: person for i, person in enumerate(labels)}\n",
        "    #\n",
        "    knn = KNeighborsClassifier(n_neighbors=3)\n",
        "    print(features.shape, identities.shape)\n",
        "    knn.fit(features, identities)\n",
        "    return knn, labels, index_to_identity\n",
        "\n",
        "\n",
        "def video_loop():\n",
        "    global knn, labels, index_to_identity\n",
        "\n",
        "    new_user = None\n",
        "    num_frames_seen = {}\n",
        "    authenticated = []\n",
        "\n",
        "    done = False\n",
        "    while (authenticated == [] or not done):\n",
        "        ret, image = video.read()\n",
        "        image = np.float32(image)\n",
        "\n",
        "        ts = time.time()\n",
        "        timestamp = datetime.fromtimestamp(ts).strftime('%H:%M:%S %Y-%m-%d')\n",
        "\n",
        "        viz_image, identities, boxes = run(knn, image, index_to_identity)\n",
        "\n",
        "        max_area = 0\n",
        "        identity_idx = 0\n",
        "        for idx, box in enumerate(boxes):\n",
        "            x1, y1, x2, y2 = box \n",
        "            area = (x2 - x1) * (y2 - y1)\n",
        "            if area > max_area:\n",
        "                max_area = area\n",
        "                identity_idx = idx\n",
        "\n",
        "        if len(identities) > 1:\n",
        "            print('Multiple faces detected, only one user can be authenticated')\n",
        "\n",
        "        identity = identities[identity_idx]\n",
        "\n",
        "        if identity in labels:\n",
        "            if identity in num_frames_seen:\n",
        "                num_frames_seen[identity] += 1\n",
        "                if num_frames_seen[identity] >= NUM_FRAMES_FOR_AUTHENTICATION:\n",
        "                    if identity not in authenticated:\n",
        "                        authenticated.append(identity)\n",
        "                        print('{} authenticated at {}'.format(\n",
        "                            identity, timestamp))\n",
        "                        done = True\n",
        "            else:\n",
        "                num_frames_seen[identity] = 1\n",
        "\n",
        "        else:\n",
        "            if new_user is None:\n",
        "                new_user = input(\n",
        "                    'Unknown user detected, please enter user name for new user: ')\n",
        "                new_user += '_{}'.format(get_randon_identifier())\n",
        "\n",
        "            save_path = os.path.join(NEW_USER_EMBEDDINGS_PATH, new_user)\n",
        "            print('Saving embeddings for {} in {}'.format(new_user, save_path))\n",
        "            if not os.path.exists(save_path):\n",
        "                os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "            num_user_images = len(os.listdir(save_path))\n",
        "            if num_user_images >= MAX_NEW_USER_IMAGES:\n",
        "                knn, labels, index_to_identity = train()\n",
        "                print('Successfull registered:', new_user)\n",
        "            dump_new_user_embedding(image, new_user, num_user_images + 1)\n",
        "\n",
        "        ret, buffer = cv2.imencode('.jpg', viz_image)\n",
        "        viz_image = buffer.tobytes()\n",
        "        yield (b'--frame\\r\\n'\n",
        "               b'Content-Type: image/jpeg\\r\\n\\r\\n' + viz_image + b'\\r\\n')  # concat frame one by one and show result\n",
        "\n",
        "    video.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template('index.html')\n",
        "\n",
        "\n",
        "@app.route('/video_feed')\n",
        "def video_feed():\n",
        "    return Response(video_loop(), mimetype='multipart/x-mixed-replace; boundary=frame')\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    if not os.path.exists(TRAIN_EMBEDDINGS_PATH):\n",
        "        os.makedirs(TRAIN_EMBEDDINGS_PATH, exist_ok=True)\n",
        "\n",
        "    if not os.path.exists(NEW_USER_EMBEDDINGS_PATH):\n",
        "        os.makedirs(NEW_USER_EMBEDDINGS_PATH, exist_ok=True)\n",
        "\n",
        "    train_identities = glob.glob(os.path.join(TRAIN_EMBEDDINGS_PATH, '*'))\n",
        "    if not train_identities:\n",
        "        print('Generating training embeddings')\n",
        "        dump_train_embeddings()\n",
        "\n",
        "    knn, labels, index_to_identity = train()\n",
        "\n",
        "    video = cv2.VideoCapture(0 + cv2.CAP_DSHOW)\n",
        "    video.set(cv2.CAP_PROP_FRAME_WIDTH,  H // SCALE)\n",
        "    video.set(cv2.CAP_PROP_FRAME_HEIGHT, W // SCALE)\n",
        "    video.set(cv2.CAP_PROP_FPS, FPS_MAX)\n",
        "    video.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*'MJPG'))\n",
        "\n",
        "    app.run(debug=False)\n"
      ]
    }
  ]
}